{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "import pandas as pd\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "dataset = load_housing_data(housing_path=HOUSING_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lib to categorial atributes\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_encoder = OneHotEncoder()\n",
    "\n",
    "#mission values\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "#Custom Transformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, X, y=None):\n",
    "        return self # nothing else to do\n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, households_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household,bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "y = dataset['median_house_value'].values\n",
    "housing = dataset.drop(\"median_house_value\", axis=1)\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    " ('imputer', SimpleImputer(strategy=\"median\")), #missin values\n",
    " ('attribs_adder', CombinedAttributesAdder()), #creating new attributes\n",
    " ('std_scaler', StandardScaler()), # scaling\n",
    " ])\n",
    "\n",
    "\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "full_pipeline = ColumnTransformer([\n",
    " (\"num\", num_pipeline, num_attribs), #num_pipeline\n",
    " (\"cat\", OneHotEncoder(), cat_attribs), #one hot encoder\n",
    " ])\n",
    "housing_prepared = full_pipeline.fit_transform(housing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset into Training Set and Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "11683    -117.99     33.86                20.0       3540.0           906.0   \n",
      "9518     -123.19     39.15                16.0       2577.0           495.0   \n",
      "14106    -117.10     32.75                23.0       1858.0           551.0   \n",
      "9479     -123.35     39.40                27.0       1321.0           338.0   \n",
      "11417    -117.96     33.70                23.0       4417.0           740.0   \n",
      "\n",
      "       population  households  median_income  median_house_value  \\\n",
      "11683      2898.0       876.0         3.0252            178000.0   \n",
      "9518       1232.0       488.0         2.6012            125600.0   \n",
      "14106      1506.0       492.0         1.7446             85200.0   \n",
      "9479        779.0       327.0         1.8500             71800.0   \n",
      "11417      1865.0       693.0         5.3428            279300.0   \n",
      "\n",
      "      ocean_proximity  \n",
      "11683       <1H OCEAN  \n",
      "9518        <1H OCEAN  \n",
      "14106      NEAR OCEAN  \n",
      "9479        <1H OCEAN  \n",
      "11417       <1H OCEAN  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = dataset['median_house_value'].values\n",
    "X = housing_prepared.copy()\n",
    "\n",
    "test_examples = np.random.choice(np.arange(len(dataset)), 5, False)\n",
    "X_test_examples = np.take(X, test_examples, axis=0)\n",
    "y_test_examples = np.take(y, test_examples, axis=0)\n",
    "\n",
    "X = np.delete(X, test_examples, axis=0)\n",
    "y = np.delete(y, test_examples, axis=0)\n",
    "\n",
    "print(dataset.iloc[test_examples])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATING LINEAR REGRESSION\n",
      "r2: 0.6293852716541182\n",
      "mean_squared_error (MSE): 4890815285.364055\n",
      "root_mean_squared_error (MSE): 69934.36412354127\n"
     ]
    }
   ],
   "source": [
    "#Training on the training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "#predicting the test results\n",
    "lin_reg_y_pred = lin_reg.predict(X_test)\n",
    "\n",
    "#Evaluating\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(\"EVALUATING LINEAR REGRESSION\")\n",
    "print(\"r2:\", r2_score(y_test, lin_reg_y_pred))\n",
    "print(\"mean_squared_error (MSE):\", mean_squared_error(y_test, lin_reg_y_pred))\n",
    "print(\"root_mean_squared_error (MSE):\", np.sqrt(mean_squared_error(y_test, lin_reg_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([171863.55150346, 160951.23355368, 147810.97715818, 147761.19868742,\n",
       "       278168.61240026])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.predict(X_test_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([178000., 125600.,  85200.,  71800., 279300.])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATING DECISION TREES\n",
      "r2: 0.6209816034514068\n",
      "mean_squared_error (MSE): 5001714247.967047\n",
      "root_mean_squared_error (MSE): 70722.79864348588\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(X_train, y_train)\n",
    "tree_reg_y_pred = tree_reg.predict(X_test)\n",
    "\n",
    "print(\"EVALUATING DECISION TREES\")\n",
    "print(\"r2:\", r2_score(y_test, tree_reg_y_pred))\n",
    "print(\"mean_squared_error (MSE):\", mean_squared_error(y_test, tree_reg_y_pred))\n",
    "print(\"root_mean_squared_error (MSE):\", np.sqrt(mean_squared_error(y_test, tree_reg_y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(X_train, y_train)\n",
    "random_reg_y_pred = forest_reg.predict(X_test)\n",
    "\n",
    "print(\"EVALUATING RANDOM FOREST\")\n",
    "print(\"r2:\", r2_score(y_test, random_reg_y_pred))\n",
    "print(\"mean_squared_error (MSE):\", mean_squared_error(y_test, random_reg_y_pred))\n",
    "print(\"root_mean_squared_error (MSE):\", np.sqrt(mean_squared_error(y_test, random_reg_y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANDOM FOREST - HYPERPARAMETER TUNNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRID SEARCH\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    " {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    " {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    " ]\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"grid_search.best_params_ : \", grid_search.best_params_)\n",
    "print(\"grid_search.best_estimator_ : \", grid_search.best_estimator_)\n",
    "\n",
    "forest_grid_search_model = grid_search.best_estimator_\n",
    "forest_grid_search_predictions = forest_grid_search_model.predict(X_test)\n",
    "\n",
    "print(\"EVALUATING RANDOM FOREST - GRID SEARCH\")\n",
    "print(\"r2:\", r2_score(y_test, forest_grid_search_predictions))\n",
    "print(\"mean_squared_error (MSE):\", mean_squared_error(y_test, forest_grid_search_predictions))\n",
    "print(\"root_mean_squared_error (MSE):\", np.sqrt(mean_squared_error(y_test, forest_grid_search_predictions)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
